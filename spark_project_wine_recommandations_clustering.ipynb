{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet: apports de Spark à la recommandation et au clustering de vins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On considère un dataset dans lequel est proposé différents vins, une note, un prix ainsi qu'une description donnée par une personne ayant gouté ce vin. Le but de ce projet est de proposer deux chaines de traitement, une sans Spark et une avec, afin de réaliser les deux opérations suivantes:\n",
    "- recommandations de vins basés sur la cosine similarité entre les descriptions des vin.\n",
    "- clustering des vins en une dizaine de cluster afin de déterminer des groupes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Link to data**:\n",
    "https://www.kaggle.com/zynicide/wine-reviews#winemag-data-130k-v2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "import collections\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csc_matrix\n",
    "from sklearn.cluster import KMeans as skKMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "import pyspark\n",
    "import findspark\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import ArrayType\n",
    "from pyspark.sql.functions import udf,col\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans as pysparkKMeans\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "PATH_TO_DATA = r\"C:/Users/assae/Documents/Cours CS/3A/OMA/Big Data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation du dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110582, 8)\n",
      "Time to extract data:  1.732569932937622\n"
     ]
    }
   ],
   "source": [
    "a = time.time()\n",
    "\n",
    "df = pd.read_csv(PATH_TO_DATA + \"winemag-data-130k-v2.csv\", index_col=0) \n",
    " \n",
    "todrop = ['designation', 'region_1', 'region_2', 'taster_name', 'taster_twitter_handle']    \n",
    "    \n",
    "df = df.drop(todrop, axis=1)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df = df.drop_duplicates(subset='title').reset_index(drop=True)\n",
    "df[[\"points\", \"price\"]] = df[[\"points\", \"price\"]].apply(pd.to_numeric)\n",
    "print(df.shape)\n",
    "\n",
    "dict_wine_description = dict(zip(list(df['title']), list(df['description'])))\n",
    "\n",
    "df.head()\n",
    "\n",
    "b = time.time()\n",
    "print(\"Time to extract data: \", b-a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Première méthode : sans Spark\n",
    "\n",
    "## 1.1. Recommandation basée sur des vins ayant une description similaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Nettoyage des descrptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stop_words = list(stopwords.words('english'))\n",
    "\n",
    "def stem(string):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    string = string.split(\" \")\n",
    "    chaine = \"\"\n",
    "    for i in range(len(string)):\n",
    "        chaine += \" \" + stemmer.stem(string[i])\n",
    "    return chaine\n",
    "\n",
    "def clean_txt(txt):\n",
    "    global stop_words\n",
    "    \n",
    "    # lower text\n",
    "    txt = txt.lower()\n",
    "    ### special escaping character '...'\n",
    "    txt = txt.replace(u'\\u2026','.')\n",
    "    txt = txt.replace(u'\\u00a0',' ')\n",
    "    ### remove non alphanumeric char\n",
    "    txt = re.sub(\"[^a-zA-Z0-9 ]\", '', txt)\n",
    "    ### remove stop words\n",
    "    txt1 = txt.split(\" \")\n",
    "    txt2 = [x for x in txt1 if x not in stop_words]\n",
    "    txt0 = \"\"\n",
    "    for i in range(len(txt2)):\n",
    "        txt0 += \" \" + txt2[i]\n",
    "    txt = txt0 \n",
    "    ### stemming\n",
    "    txt = stem(txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is ripe and fruity, a wine that is smooth while still structured. Firm tannins are filled out with juicy red berry fruits and freshened with acidity. It's  already drinkable, although it will certainly be better from 2016.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'  ripe fruiti wine smooth still structur firm tannin fill juici red berri fruit freshen acid  alreadi drinkabl although certain better 2016'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "title = df['title'][0]\n",
    "\n",
    "print(dict_wine_description[title])\n",
    "clean_txt(dict_wine_description[title])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_descriptions(dico):\n",
    "    a = time.time()\n",
    "    cleaned = []\n",
    "    keys = list(dico.keys())\n",
    "    values = list(dico.values())\n",
    "    for i in range(len(values)):\n",
    "        cleaned.append(clean_txt(values[i]))\n",
    "    b = time.time()\n",
    "    print(\"Time to clean the descriptions : \", b-a)  \n",
    "    return dict(zip(keys, cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to clean the descriptions :  62.47929859161377\n"
     ]
    }
   ],
   "source": [
    "dict_cleaned_descriptions = clean_descriptions(dict_wine_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. Vectorisation des descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(dict_wines):\n",
    "    a = time.time()\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(list(dict_wines.values()))\n",
    "    b = time.time()\n",
    "    print(\"Time to encode descriptions : \", b-a)\n",
    "    return dict(zip(list(dict_wines.keys()), X)), X\n",
    "\n",
    "def tf_idf(dict_wines):\n",
    "    a = time.time()\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(list(dict_wines.values()))\n",
    "    b = time.time()\n",
    "    print(\"Time to encode descriptions : \", b-a)\n",
    "    return dict(zip(list(dict_wines.keys()), X)), X\n",
    "\n",
    "def hachage(dict_wines):\n",
    "    a = time.time()\n",
    "    values = list(dict_wines.values())\n",
    "    tohash = []\n",
    "    for sent in values:\n",
    "        cnt = collections.Counter()\n",
    "        for word in sent.split():\n",
    "            cnt[word] += 1\n",
    "        tohash.append(dict(cnt))\n",
    "    h = FeatureHasher(n_features=10)\n",
    "    X = h.transform(tohash)\n",
    "    b = time.time()\n",
    "    print(\"Time to encode descriptions : \", b-a)\n",
    "    return dict(zip(list(dict_wines.keys()), X)), X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to encode descriptions :  3.187100887298584\n"
     ]
    }
   ],
   "source": [
    "title = df['title'][0]\n",
    "a,b = one_hot_encoding(dict_cleaned_descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3. Recommandations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(v1, v2):\n",
    "    cos_sim = np.dot(v1, v2) / (np.linalg.norm(v1)*np.linalg.norm(v2))\n",
    "    return cos_sim\n",
    "\n",
    "\n",
    "def recom_knn(wine, dict_wines, k, model):\n",
    "    keys = list(dict_wines.keys())\n",
    "    if model == 'one-hot':\n",
    "        dict_encoding, encoding = one_hot_encoding(dict_wines)\n",
    "    elif model == 'tfidf':\n",
    "        dict_encoding, encoding = tf_idf(dict_wines)\n",
    "    elif model == 'hash':\n",
    "        dict_encoding, encoding = hachage(dict_wines)\n",
    "    else:\n",
    "        print(\"Model can be 'one-hot', 'tfidf', or 'hash' only\")\n",
    "        return None\n",
    "    a = time.time()\n",
    "    scores = []\n",
    "    values = list(dict_encoding.values())\n",
    "    for i in range(len(dict_encoding)):\n",
    "        considered_wine = np.array(dict_encoding[wine].todense())[0]\n",
    "        scores.append(score(considered_wine, np.array(values[i].todense())[0]))\n",
    "    sorted_index = np.argsort(-np.array(scores))\n",
    "    wines = []\n",
    "    for j in range(1, k+1):\n",
    "        wines.append((keys[sorted_index[j]], scores[sorted_index[j]]))\n",
    "    b = time.time()\n",
    "    print(\"Time to compute cosinus similarities : \", b-a)\n",
    "    return wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quinta dos Avidagos 2011 Avidagos Red (Douro)\n",
      "Time to encode descriptions :  3.210298538208008\n",
      "Time to compute cosinus similarities :  32.19903612136841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Enoport 2015 Vilalva Reserva Red (Douro)', 0.5821817364274594),\n",
       " ('Château de Pizay 2014  Régnié', 0.5455447255899809),\n",
       " ('Les Frères Perroud 2014 Vieilles Vignes  (Brouilly)', 0.5238095238095238),\n",
       " ('Château Bertinerie 2011 Grande Cuvée  (Blaye Côtes de Bordeaux)',\n",
       "  0.5238095238095238),\n",
       " ('Domaine Chasselay 2010 Les Grands Eparcieux  (Beaujolais)',\n",
       "  0.5238095238095238),\n",
       " ('Domaine les Pins 2012 Le Clos Cabernet Franc (Bourgueil)',\n",
       "  0.5135525910130956),\n",
       " ('Schröder & Schÿler 2012 Private Réserve  (Médoc)', 0.5095101710852534),\n",
       " ('Manuel Olivier 2012  Pommard', 0.5039526306789697),\n",
       " ('Château Bélingard 2012 Réserve Red (Côtes de Bergerac)',\n",
       "  0.5039526306789697),\n",
       " ('Casa Santos Lima 2012 Quinta dos Bons Ventos Red (Lisboa)',\n",
       "  0.5006261743217588)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = df['title'][0]\n",
    "print(title)\n",
    "recom_knn(title, dict_cleaned_descriptions, 10, 'one-hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quinta dos Avidagos 2011 Avidagos Red (Douro)\n",
      "Time to encode descriptions :  3.6084554195404053\n",
      "Time to compute cosinus similarities :  29.895278215408325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Enoport 2015 Vilalva Reserva Red (Douro)', 0.49097115516236123),\n",
       " ('Joseph Drouhin 2012  Moulin-à-Vent', 0.42944709961586114),\n",
       " ('Casa Santos Lima 2012 Quinta dos Bons Ventos Red (Lisboa)',\n",
       "  0.4246471882115379),\n",
       " (\"Fabien Collonge 2014 L'Aurore des Côtes  (Chiroubles)\", 0.4010955738952229),\n",
       " ('Les Frères Perroud 2014 Vieilles Vignes  (Brouilly)', 0.39931391451266035),\n",
       " ('Château Taussin 2014 Premium  (Bordeaux)', 0.39754375425327115),\n",
       " (\"Emile Beyer 2013 L'Hostellerie Pinot Gris (Alsace)\", 0.39257398556680123),\n",
       " ('Antonin Rodet 2011 Château de Mercey  (Santenay)', 0.39225414809727677),\n",
       " ('Château Coutinel 2011 Red (Fronton)', 0.3916813309252866),\n",
       " ('Cave de Saumur 2014 Réserve des Vignerons  (Saumur)', 0.383444784144407)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = df['title'][0]\n",
    "print(title)\n",
    "recom_knn(title, dict_cleaned_descriptions, 10, 'tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quinta dos Avidagos 2011 Avidagos Red (Douro)\n",
      "Time to encode descriptions :  3.287447690963745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\assae\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute cosinus similarities :  4.988306522369385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('CARM 2005 Reserva Red (Douro)', 0.9772545497599154),\n",
       " ('Château Jeanguillon 2014  Bordeaux Supérieur', 0.9713237285143653),\n",
       " ('Columbia Crest 2009 Two Vines Pinot Grigio (Washington)',\n",
       "  0.9607689228305228),\n",
       " ('Manciat-Poncet 2014 Les Crays  (Pouilly-Fuissé)', 0.9607689228305228),\n",
       " ('Wellington 2004 Estate Merlot (Sonoma Valley)', 0.9502621934663978),\n",
       " ('Quinta do Crasto 2012 Flor de Crasto Red (Douro)', 0.949157995752499),\n",
       " ('Château de Gaudou 2010 Grand Lignée Malbec-Merlot (Cahors)',\n",
       "  0.9467292624062573),\n",
       " ('Château de Santenay 2013  Mercurey', 0.9435641951204965),\n",
       " ('Steininger 2011 Rosé Sekt Cabernet Sauvignon (Österreichischer Sekt)',\n",
       "  0.9435641951204965),\n",
       " ('Canard-Duchêne NV Charles VII Grande Cuvée de la Rosé Brut  (Champagne)',\n",
       "  0.9433700705169153)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = df['title'][0]\n",
    "print(title)\n",
    "recom_knn(title, dict_cleaned_descriptions, 10, 'hash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Clustering des vins en prenant en compte l'ensemble des informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_wines(data, clean_dict_wines, model='tfidf', nb_clusters=10):\n",
    "    if model == 'one-hot':\n",
    "        dict_encoding, encoding = one_hot_encoding(clean_dict_wines)\n",
    "        a = time.time()\n",
    "        pca_subs = TruncatedSVD(n_components=50)\n",
    "        reduced_encoding = pd.DataFrame(pca_subs.fit_transform(encoding))\n",
    "        b = time.time()\n",
    "        pca_time = b-a\n",
    "    elif model == 'tfidf':\n",
    "        a = time.time()\n",
    "        dict_encoding, encoding = tf_idf(clean_dict_wines)\n",
    "        pca_subs = TruncatedSVD(n_components=50)\n",
    "        reduced_encoding = pd.DataFrame(pca_subs.fit_transform(encoding))\n",
    "        b = time.time()\n",
    "        pca_time = b-a\n",
    "    elif model == 'hash':\n",
    "        dict_encoding, encoding = hachage(clean_dict_wines)\n",
    "        a = time.time()\n",
    "        reduced_encoding = pd.DataFrame(encoding.todense())\n",
    "        b = time.time()\n",
    "        pca_time = b-a\n",
    "    else:\n",
    "        print(\"Model can be 'one-hot', 'tfidf', or 'hash' only\")\n",
    "        return None\n",
    "    c = time.time()\n",
    "    df_clustering = pd.concat([df[\"points\"], df[\"price\"], pd.get_dummies(df[\"country\"]), pd.get_dummies(df[\"province\"]), pd.get_dummies(df[\"variety\"]), reduced_encoding], axis = 1)\n",
    "    clustering = skKMeans(n_clusters=nb_clusters)\n",
    "    clustered = clustering.fit_predict(df_clustering)\n",
    "    df_final = pd.concat([df[\"title\"], pd.DataFrame(clustered, columns=['cluster'])], axis=1)  \n",
    "    d = time.time()\n",
    "    print(\"Time for clustering: \", d-c+pca_time)\n",
    "    return df_final        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to encode descriptions :  3.6558380126953125\n",
      "Time for clustering:  155.63385343551636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    46515\n",
       "7    31201\n",
       "2    20922\n",
       "8     8960\n",
       "4     2199\n",
       "1      559\n",
       "5      179\n",
       "9       38\n",
       "6        6\n",
       "3        3\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = clustering_wines(df, dict_cleaned_descriptions, model='one-hot', nb_clusters=10)\n",
    "df_final['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to encode descriptions :  4.033212661743164\n",
      "Time for clustering:  151.19664549827576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    48724\n",
       "9    34472\n",
       "2    18676\n",
       "5     6142\n",
       "1     1921\n",
       "6      438\n",
       "3      162\n",
       "8       37\n",
       "4        7\n",
       "7        3\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = clustering_wines(df, dict_cleaned_descriptions, model='tfidf', nb_clusters=10)\n",
    "df_final['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to encode descriptions :  3.962859630584717\n",
      "Time for clustering:  158.92983031272888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    48168\n",
       "5    33748\n",
       "8    18564\n",
       "0     7400\n",
       "4     2054\n",
       "6      439\n",
       "2      163\n",
       "7       37\n",
       "9        6\n",
       "3        3\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = clustering_wines(df, dict_cleaned_descriptions, model='hash', nb_clusters=10)\n",
    "df_final['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Deuxième méthode : avec Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init(\"C:/spark/spark-2.3.2-bin-hadoop2.7\")\n",
    "sc=pyspark.SparkContext(\"local[*]\",\"Project\")\n",
    "sqlc=SQLContext(sc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to extract data: 23.030930757522583\n"
     ]
    }
   ],
   "source": [
    "a = time.time()\n",
    "\n",
    "sdf = sqlc.read.csv(PATH_TO_DATA + \"winemag-data-130k-v2.csv\", header=True)\n",
    "\n",
    "todrop = ['designation', 'region_1', 'region_2', 'taster_name', 'taster_twitter_handle']\n",
    "\n",
    "for c in todrop:\n",
    "    sdf = sdf.drop(c)\n",
    "    \n",
    "sdf = sdf.na.drop()\n",
    "sdf = sdf.dropDuplicates(['title'])\n",
    "sdf.count()\n",
    "\n",
    "b = time.time()\n",
    "\n",
    "print(\"Time to extract data:\", b-a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Recommandation basée sur des vins ayant une description similaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. Traitement du texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(liste):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    l2 = []\n",
    "    for i in range(len(liste)):\n",
    "        l2.append(stemmer.stem(liste[i]))\n",
    "    return l2\n",
    "\n",
    "def clean_txt(df):\n",
    "    a = time.time()\n",
    "    regexTokenizer = RegexTokenizer(inputCol=\"description\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "    df = regexTokenizer.transform(df)\n",
    "    df = df.drop('description')\n",
    "    remover = StopWordsRemover(inputCol=\"words\", outputCol=\"desc\")\n",
    "    df = remover.transform(df)\n",
    "    df = df.drop('words')\n",
    "    fct = udf(lambda x: stem(x), ArrayType(StringType()))\n",
    "    df = df.withColumn(\"description\", fct(\"desc\"))\n",
    "    df = df.drop('desc')\n",
    "    b = time.time()\n",
    "    print(\"Time to clean the descriptions : \", b-a)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to clean the descriptions :  1.8364968299865723\n"
     ]
    }
   ],
   "source": [
    "sdfc = clean_txt(sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. Vectorisation des descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(df):\n",
    "    a = time.time()\n",
    "    hashingTF = HashingTF(inputCol=\"description\", outputCol=\"rawFeatures\", numFeatures=10)\n",
    "    df = hashingTF.transform(df)\n",
    "    idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "    idfModel = idf.fit(df)\n",
    "    df = idfModel.transform(df)\n",
    "    df = df.drop('description')\n",
    "    df = df.drop('rawFeatures')\n",
    "    b = time.time()\n",
    "    print(\"Time to encode the descriptions : \", b-a)\n",
    "    return df\n",
    "\n",
    "def word2vec(df):\n",
    "    a = time.time()\n",
    "    word2Vec = Word2Vec(vectorSize=10, minCount=0, inputCol=\"description\", outputCol=\"features\")\n",
    "    model = word2Vec.fit(df)\n",
    "    df = model.transform(df)\n",
    "    df = df.drop('description')\n",
    "    b = time.time()\n",
    "    print(\"Time to encode the descripions : \", b-a)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to encode the descriptions :  285.72354221343994\n"
     ]
    }
   ],
   "source": [
    "sdf_tfidf = tfidf(sdfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to encode the descripions :  599.2327582836151\n"
     ]
    }
   ],
   "source": [
    "sdf_w2v = word2vec(sdfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3. Recommandations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(v1, v2):\n",
    "    cos_sim = np.dot(v1, v2) / (np.linalg.norm(v1)*np.linalg.norm(v2))\n",
    "    return cos_sim\n",
    "\n",
    "def reco_spark(wine_name, sdf, k=10, model='tfidf'):\n",
    "    a = time.time()\n",
    "    try:\n",
    "        sdf.createTempView(model)\n",
    "        df = sqlc.sql(\"SELECT title, features FROM \" + model).toPandas()\n",
    "    except:\n",
    "        df = sqlc.sql(\"SELECT title, features FROM \" + model).toPandas()\n",
    "    b = time.time()\n",
    "    print(\"Time to select the data :\", b-a)\n",
    "    c  = time.time()\n",
    "    l = zip(list(df['title']), list(df['features']))\n",
    "    rdd = sc.parallelize(l)\n",
    "    wine_encoding = list(df[df['title'] == wine_name].features)[0]\n",
    "    rdd1 = rdd.map(lambda s: (s[0], score(s[1], wine_encoding)))\n",
    "    d  = time.time()\n",
    "    print(\"Time for similiraty calculations :\", d-c)\n",
    "    rdd2 = rdd1.sortBy(lambda x: -x[1])\n",
    "    e = time.time()\n",
    "    print(\"Time to sort results :\", e-d)\n",
    "    final = rdd2.take(k)\n",
    "    f = time.time()\n",
    "    print(\"Time to collect results :\", f-e)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to select the data : 287.59312176704407\n",
      "Time for similiraty calculations : 0.6919095516204834\n",
      "Time to sort results : 70.39353370666504\n",
      "Time to collect results : 34.79569673538208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Quinta dos Avidagos 2011 Avidagos Red (Douro)', 0.9999999999999999),\n",
       " ('Edmeades 2011 Zinfandel (Mendocino County)', 0.9643488391799788),\n",
       " ('Winzerkeller Andau 2013 St. Laurent (Burgenland)', 0.9622234035643586),\n",
       " ('Manuel Olivier 2011  Bourgogne', 0.9608204941230747),\n",
       " ('Casal do Conde 2012 Quinta da Arrancosa Moscatel Graúdo (Tejo)',\n",
       "  0.9591004951560843),\n",
       " ('F X Pichler 2006 Von de Terrassen Federspiel Riesling (Wachau)',\n",
       "  0.9590022053156014),\n",
       " ('Maryhill 2009 Cabernet Sauvignon (Columbia Valley (WA))',\n",
       "  0.956376213374129),\n",
       " ('Apsara 2014 Kick Ranch Sauvignon Blanc (Sonoma County)',\n",
       "  0.9527419069308315),\n",
       " ('Harlow Ridge 2011 Chardonnay (Lodi)', 0.9520437122175613),\n",
       " ('Quinta do Casal Branco 2015 Tinto Red (Tejo)', 0.9508761648408962)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = 'Quinta dos Avidagos 2011 Avidagos Red (Douro)'\n",
    "reco_spark(wine, sdf_tfidf, k=10, model='tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to select the data : 230.6880075931549\n",
      "Time for similiraty calculations : 0.3878154754638672\n",
      "Time to sort results : 8.374927282333374\n",
      "Time to collect results : 5.355997800827026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Quinta dos Avidagos 2011 Avidagos Red (Douro)', 1.0),\n",
       " ('Wines & Winemakers 2011 Companhia das Lezírias Catapereiro Red (Tejo)',\n",
       "  0.9959854052114829),\n",
       " (\"Poças 2013 Coroa d'Ouro Red (Douro)\", 0.9938831789197227),\n",
       " ('Château du Perier 2011  Médoc', 0.993788320104824),\n",
       " ('Château Lestage 2013  Listrac-Médoc', 0.9931340478901978),\n",
       " ('Antonin Rodet 2011 Château de Mercey  (Santenay)', 0.99267374176346),\n",
       " ('Cave du Marmandais 2014 Château Campot Lafont  (Bordeaux)',\n",
       "  0.9924307669793289),\n",
       " ('Château Peneau 2015 Cuvée Tradition  (Côtes de Bordeaux)',\n",
       "  0.9922441143723999),\n",
       " ('Château Beauséjour 2014  Fronsac', 0.9915758324828349),\n",
       " ('Louis Max 2014 Domaine la Marche  (Mercurey)', 0.9914636322257657)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = 'Quinta dos Avidagos 2011 Avidagos Red (Douro)'\n",
    "reco_spark(wine, sdf_w2v, k=10, model='w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Clustering des vins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_features(sdf):\n",
    "    a = time.time()\n",
    "    sdf = sdf.drop('winery')\n",
    "    sdf = sdf.drop('title')\n",
    "    sdf = sdf.drop('_c0')\n",
    "    to_encode = ['country', 'province', 'variety']\n",
    "    for cat in to_encode:\n",
    "        stringIndexer = StringIndexer(inputCol=cat, outputCol=cat + \"Index\")\n",
    "        model = stringIndexer.fit(sdf)\n",
    "        indexed = model.transform(sdf)\n",
    "        encoder = OneHotEncoder(inputCol=cat + \"Index\", outputCol=cat + \"Vec\")\n",
    "        sdf = encoder.transform(indexed)\n",
    "        sdf = sdf.drop(cat)\n",
    "        sdf = sdf.drop(cat+'Index')\n",
    "    sdf = sdf.withColumn(\"points\", sdf[\"points\"].cast(FloatType()))\n",
    "    sdf = sdf.withColumn(\"price\", sdf[\"price\"].cast(FloatType()))\n",
    "    sdf = sdf.na.drop()\n",
    "    assembler = VectorAssembler(inputCols=[\"provinceVec\", \"countryVec\", \"varietyVec\", \"features\", \"points\", \"price\"], outputCol=\"feat\")\n",
    "    output = assembler.transform(sdf)\n",
    "    for cat in [\"provinceVec\", \"countryVec\", \"varietyVec\", \"features\", \"points\", \"price\"]:\n",
    "        output = output.drop(cat)\n",
    "    b = time.time()\n",
    "    print(\"Time to prepare the dataset for clustering : \", b-a)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to prepare the dataset for clustering :  22.97869563102722\n"
     ]
    }
   ],
   "source": [
    "sdf_enc_tfidf = encode_categorical_features(sdf_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to prepare the dataset for clustering :  20.17354416847229\n"
     ]
    }
   ],
   "source": [
    "sdf_enc_w2v = encode_categorical_features(sdf_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(sdf):\n",
    "    a = time.time()\n",
    "    kmeans = pysparkKMeans(featuresCol='feat', predictionCol='prediction', k=10)\n",
    "    model = kmeans.fit(sdf)\n",
    "    predictions = model.transform(sdf)\n",
    "    b = time.time()\n",
    "    print(\"Time for clustering : \", b-a)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for clustering :  280.6621174812317\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|         1|    7|\n",
      "|         6|  140|\n",
      "|         3|32840|\n",
      "|         5| 1281|\n",
      "|         9|12276|\n",
      "|         4|  350|\n",
      "|         8| 4039|\n",
      "|         7|  120|\n",
      "|         2|   33|\n",
      "|         0|59471|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_tfidf = clustering(sdf_enc_tfidf)\n",
    "predictions_tfidf.groupBy('prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for clustering :  273.58593583106995\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|         1|    7|\n",
      "|         6|  140|\n",
      "|         3|32840|\n",
      "|         5| 1281|\n",
      "|         9|12276|\n",
      "|         4|  350|\n",
      "|         8| 4039|\n",
      "|         7|  120|\n",
      "|         2|   33|\n",
      "|         0|59471|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_w2v = clustering(sdf_enc_w2v)\n",
    "predictions_w2v.groupBy('prediction').count().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
